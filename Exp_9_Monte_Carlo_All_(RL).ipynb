{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LoKe220723/Reinforcement-Learning/blob/main/Exp_9_Monte_Carlo_All_(RL).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MONTE CARLO**"
      ],
      "metadata": {
        "id": "mDjHsOcj5ZxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ep1: A+3 A+2 B-4 A+4 B-3 <br>\n",
        "Ep2: B-2 A+3 B-3"
      ],
      "metadata": {
        "id": "Y8PUJAXONEZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **FIRST VISIT**"
      ],
      "metadata": {
        "id": "Gr5lsOYI5Zjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_episode(i):\n",
        "    episode_pattern = input(f\"Enter the episode {i}: \").split()\n",
        "    episode = []\n",
        "    for step in episode_pattern:\n",
        "        state = step[0]\n",
        "        reward = int(step[1:])\n",
        "        episode.append((state, reward))\n",
        "    return episode\n",
        "\n",
        "def monte_carlo_first_visit(episodes):\n",
        "    returns = {}\n",
        "    state_count = {}\n",
        "    state_values = {}\n",
        "\n",
        "    for episode in episodes:\n",
        "        states, rewards = zip(*episode)\n",
        "        total_return = 0\n",
        "\n",
        "        for t in range(len(states) - 1, -1, -1):\n",
        "            state = states[t]\n",
        "            total_return += rewards[t]\n",
        "            if state not in states[:t]:\n",
        "                if state in returns:\n",
        "                    returns[state].append(total_return)\n",
        "                else:\n",
        "                    returns[state] = [total_return]\n",
        "                state_count[state] = len(returns[state])\n",
        "                state_values[state] = sum(returns[state]) / state_count[state]\n",
        "\n",
        "    return state_values\n",
        "\n",
        "def main():\n",
        "    num_episodes = int(input(\"Enter the number of episodes: \"))\n",
        "    episodes = []\n",
        "    for i in range(num_episodes):\n",
        "        episode = generate_episode(i+1)\n",
        "        episodes.append(episode)\n",
        "\n",
        "    state_values = monte_carlo_first_visit(episodes)\n",
        "\n",
        "    print(\"Estimated state values:\")\n",
        "    for state, value in state_values.items():\n",
        "        print(f\"State {state}: {value}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rMcIenpMTJs",
        "outputId": "29a148a7-8b0d-4bc5-fa88-8720209c8be8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of episodes: 2\n",
            "Enter the episode 1: A+3 A+2 B-4 A+4 B-3\n",
            "Enter the episode 2: B-2 A+3 B-3\n",
            "Estimated state values:\n",
            "State B: -2.5\n",
            "State A: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EVERY VISIT**"
      ],
      "metadata": {
        "id": "eDIrMpWiNPLW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "gamma = 1.0\n",
        "\n",
        "def generate_episode(i):\n",
        "    episode_pattern = input(f\"Enter the episode {i}: \").split()\n",
        "    episode = []\n",
        "    for step in episode_pattern:\n",
        "        state = step[0]\n",
        "        reward = int(step[1:])\n",
        "        episode.append((state, reward))\n",
        "    return episode\n",
        "\n",
        "def calculate_return(episode, t):\n",
        "    G = 0\n",
        "    for i in range(t, len(episode)):\n",
        "        reward = episode[i][1]\n",
        "        G = G + (gamma ** (i - t)) * reward\n",
        "    return G\n",
        "\n",
        "def monte_carlo_every_visit(episodes):\n",
        "    state_values = {}\n",
        "    returns_sum = {}\n",
        "    state_counts = {}\n",
        "\n",
        "    for episode in episodes:\n",
        "        for t in range(len(episode)):\n",
        "            state = episode[t][0]\n",
        "            if state not in state_counts:\n",
        "                state_counts[state] = 0\n",
        "            state_counts[state] += 1\n",
        "\n",
        "            G = calculate_return(episode, t)\n",
        "\n",
        "            if state not in returns_sum:\n",
        "                returns_sum[state] = 0\n",
        "            returns_sum[state] += G\n",
        "\n",
        "            state_values[state] = returns_sum[state] / state_counts[state]\n",
        "\n",
        "    return state_values\n",
        "\n",
        "def main():\n",
        "    num_episodes = int(input(\"Enter the number of episodes: \"))\n",
        "    episodes = []\n",
        "    for i in range(num_episodes):\n",
        "        episode = generate_episode(i + 1)\n",
        "        episodes.append(episode)\n",
        "\n",
        "    state_values = monte_carlo_every_visit(episodes)\n",
        "\n",
        "    print(\"Estimated state values:\")\n",
        "    for state, value in state_values.items():\n",
        "        print(f\"State {state}: {value}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "# A+3 A+2 B-4 A+4 B-3\n",
        "# B-2 A+3 B-3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptRHHDf0NRVJ",
        "outputId": "deb2bb22-b6be-4ba7-cc57-805693e03087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of episodes: 2\n",
            "Enter the episode 1: A+3 A+2 B-4 A+4 B-3\n",
            "Enter the episode 2: B-2 A+3 B-3\n",
            "Estimated state values:\n",
            "State A: 0.5\n",
            "State B: -2.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **BOTH**"
      ],
      "metadata": {
        "id": "DWZcSKvpNUAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "gamma = 1.0\n",
        "\n",
        "def generate_episode(i):\n",
        "    episode_pattern = input(f\"Enter the episode {i}: \").split()\n",
        "    episode = []\n",
        "    for step in episode_pattern:\n",
        "        state = step[0]\n",
        "        reward = int(step[1:])\n",
        "        episode.append((state, reward))\n",
        "    return episode\n",
        "\n",
        "def monte_carlo_first_visit(episodes):\n",
        "    returns = {}\n",
        "    state_count = {}\n",
        "    state_values = {}\n",
        "\n",
        "    for episode in episodes:\n",
        "        states, rewards = zip(*episode)\n",
        "        total_return = 0\n",
        "\n",
        "        for t in range(len(states) - 1, -1, -1):\n",
        "            state = states[t]\n",
        "            total_return += rewards[t]\n",
        "            if state not in states[:t]:\n",
        "                if state in returns:\n",
        "                    returns[state].append(total_return)\n",
        "                else:\n",
        "                    returns[state] = [total_return]\n",
        "                state_count[state] = len(returns[state])\n",
        "                state_values[state] = sum(returns[state]) / state_count[state]\n",
        "\n",
        "    return state_values\n",
        "\n",
        "def calculate_return(episode, t):\n",
        "    G = 0\n",
        "    for i in range(t, len(episode)):\n",
        "        reward = episode[i][1]\n",
        "        G = G + (gamma ** (i - t)) * reward\n",
        "    return G\n",
        "\n",
        "def monte_carlo_every_visit(episodes):\n",
        "    state_values = {}\n",
        "    returns_sum = {}\n",
        "    state_counts = {}\n",
        "\n",
        "    for episode in episodes:\n",
        "        for t in range(len(episode)):\n",
        "            state = episode[t][0]\n",
        "            if state not in state_counts:\n",
        "                state_counts[state] = 0\n",
        "            state_counts[state] += 1\n",
        "\n",
        "            G = calculate_return(episode, t)\n",
        "\n",
        "            if state not in returns_sum:\n",
        "                returns_sum[state] = 0\n",
        "            returns_sum[state] += G\n",
        "\n",
        "            state_values[state] = returns_sum[state] / state_counts[state]\n",
        "\n",
        "    return state_values\n",
        "\n",
        "def main():\n",
        "    num_episodes = int(input(\"Enter the number of episodes: \"))\n",
        "    episodes = []\n",
        "    for i in range(num_episodes):\n",
        "        episode = generate_episode(i+1)\n",
        "        episodes.append(episode)\n",
        "\n",
        "    visit = int(input(\"Choose either 1. First Visit or 2. Every Visit: \"))\n",
        "    if visit == 1:\n",
        "      state_values = monte_carlo_first_visit(episodes)\n",
        "    elif visit == 2:\n",
        "      state_values = monte_carlo_every_visit(episodes)\n",
        "    else:\n",
        "      print(\"Error: choose either 1. First Visit or 2. Every Visit.\")\n",
        "      return\n",
        "\n",
        "    print(\"Estimated state values:\")\n",
        "    for state, value in state_values.items():\n",
        "        print(f\"State {state}: {value}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "# A+3 A+2 B-4 A+4 B-3\n",
        "# B-2 A+3 B-3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFyT8PqdcA9s",
        "outputId": "196e0907-63df-4365-c030-b2b767e2220f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of episodes: 2\n",
            "Enter the episode 1: A+3 A+2 B-4 A+4 B-3\n",
            "Enter the episode 2: B-2 A+3 B-3\n",
            "Choose either 1. First Visit or 2. Every Visit: 2\n",
            "Estimated state values:\n",
            "State A: 0.5\n",
            "State B: -2.75\n"
          ]
        }
      ]
    }
  ]
}